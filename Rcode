########################################################
#   Statistical analysis R code for manuscript:        #
#   Toxopeus, Gadey, Andaloori, Sanaei & Ragland       #    
#   'Costs of averting diapause associated with slow   #
#   decline of metabolic rates at low temperature'     #
########################################################

#All data are available as a supplementary Excel file
#associated with the manuscript itself. This Excel file
#contains explanations of all abbreviations and variable names.
#Each worksheet in the Excel filecan be saved as its own  
#.csv or .txt file for use in the code below.

########################################################
#                                                      #
#        Metabolic rate at 4 and 25 C                  #
#                                                      #
########################################################

#read in data
my.data <- read.csv("MRat4and25C.csv", stringsAsFactors = FALSE)
str(my.data)

##subset data into the two experiments
NDvD.data <- subset(my.data, my.data$Age.at.chilling=="10 d")
SDvD.data <- subset(my.data, my.data$Age.at.chilling="10 d")

############# Diapause vs. non-diapause ###############

#1. Restructure data to make temperature a column variable

NDvD.cold <- cbind(NDvD.data$Pupa.ID, NDvD.data$Classification, NDvD.data$Mass..mg.,
                   NDvD.data$MRat4C..ul.h., log(NDvD.data$MRat4C..ul.h.), rep(4,length(NDvD.data$Pupa.ID)))
NDvD.warm <- cbind(NDvD.data$Pupa.ID, NDvD.data$Classification, NDvD.data$Mass..mg.,
                   NDvD.data$MRat25C..ul.h., log(NDvD.data$MRat25C..ul.h.), rep(25,length(NDvD.data$Pupa.ID)))
NDvD.data2 <- as.data.frame(rbind(NDvD.cold, NDvD.warm))
colnames(NDvD.data2) <- c("Pupa.ID", "Classification", "Mass", "MR", "logMR", "Temperature")
NDvD.data2$Mass <- as.numeric(as.character(NDvD.data2$Mass))
NDvD.data2$MR <- as.numeric(as.character(NDvD.data2$MR))
NDvD.data2$logMR <- as.numeric(as.character(NDvD.data2$logMR))
NDvD.data2$Temperature <- as.numeric(as.character(NDvD.data2$Temperature))


#2. Fit nonlinear mixed models for met rate

library(lme4)

#random slopes and random intercepts model
# can't fit because there's inadequate reps to fit individual slopes for each pupa
# fm<-lmer( log(MR) ~ Classification*Temperature + Mass..mg. + (1+Temperature|Pupa.ID), data=NDvD.data) 

#random intercepts model -- this is estimable because theres at least (and in fact exactly) two replicated per subject (pupa)
fm<-lmer(logMR ~ Classification*Temperature + Mass + (1|Pupa.ID), data=NDvD.data2) 
summary(fm)

#test fixed effects using 
drop1(fm)

# boundary (singular) fit: see ?isSingular
# Single term deletions
# 
# Model:
#   logMR ~ Classification * Temperature + Mass + (1 | Pupa.ID)
# npar    AIC
# <none>                          138.99
# Mass                          1 169.98
# Classification:Temperature    1 220.32

## the output suggests that the full model with the interaction and 
##including the body mass covariate is the best fit (lowest AIC). 

#3. Estimate slopes of model terms using contrasts

#create contrast vectors; the columns in the design matrix are:
#  Intercept, ClassificationND, Temperature, Mass, and Classification:Temperature
conMat<-cbind(c(0,0,1,0,0),
              c(0,0,1,0,1))
colnames(conMat)<-c('SlopeForDia','SlopeForND')
# First column is the contrast vector estimating the slope for diapause, second column for non-diapause

library(multcomp)
a<-glht(fm,linfct=t(conMat))
summary(a)

# Simultaneous Tests for General Linear Hypotheses

# Fit: lmer(formula = log(MR) ~ Classification * Temperature + Mass..mg. + 
#             (1 | Pupa.ID), data = NDvD.data2)
# 
# Linear Hypotheses:
#   Estimate Std. Error z value Pr(>|z|)    
# SlopeForDia == 0 0.074102   0.003360   22.05   <1e-10 ***
#   SlopeForND == 0  0.132808   0.003985   33.33   <1e-10 ***
#   ---
#   Signif. codes:  0 â***â 0.001 â**â 0.01 â*â 0.05 â.â 0.1 â â 1
# (Adjusted p values reported -- single-step method)

## Above, 0.074 and 0.133 are the slope estimated for diapause and non-diapause, respectively.

#4. Calculate point estimate of Q10

#The above slopes are for log(MR) as a function of temperature.
#To convert these slopes into Q10 values, we use:
#log(Q10) = 10*slope(fold-change in log(MR) with a 10 degree increase in temperature)
#Q10 = exp(10*slope)

Q10.D <- exp(10*0.074102)
Q10.ND <- exp(10*0.132808)

#print values
c(Q10.D, Q10.ND)
#2.098074, 3.773791

#5. Calculate confidence intervals for Q10

confint(a)
# Simultaneous Confidence Intervals
# 
# Fit: lmer(formula = logMR ~ Classification * Temperature + Mass + 
#             (1 | Pupa.ID), data = NDvD.data2)
# 
# Quantile = 2.2364
# 95% family-wise confidence level
# 
# 
# Linear Hypotheses:
#                 Estimate  lwr     upr    
# SlopeForDia == 0 0.07410  0.06659 0.08162
# SlopeForND == 0  0.13281  0.12390 0.14172

b<-confint(a)
mat<-b$confint

##diapause

#point estimate Q10
intercept<-fixef(fm)[1]
exp( coef(a)[1]*10+intercept )/exp(intercept)
# 2.098067 # same as calculated in step 4

#lower 95%CI
exp( mat[1,2]*10 + intercept) / exp(intercept)
# 1.946169 

#upper 95%CI
exp( mat[1,3]*10 + intercept) / exp(intercept)
# 2.261821

## non-diapause

#point estimate Q10
intercept<-fixef(fm)[1] + fixef(fm)[2]
exp( coef(a)[2]*10+intercept )/exp(intercept)
# 3.773784 # same as calculated in step 4

#lower 95%CI
exp( mat[2,2]*10 + intercept) / exp(intercept)
# 3.45201

#upper 95%CI
exp( mat[2,3]*10 + intercept) / exp(intercept)
# 4.12555

## so, 95% CIs are 1.95 - 2.26  (Diapause) and 3.45 - 4.13 (Non-Diapause)


############# Diapause vs. shallow diapause ###############

#1. Restructure data to make temperature a column variable

SDvD.cold <- cbind(SDvD.data$Pupa.ID, SDvD.data$Classification, SDvD.data$Mass..mg.,
                   SDvD.data$MRat4C..ul.h., log(SDvD.data$MRat4C..ul.h.), rep(4,length(SDvD.data$PupaID)))
SDvD.warm <- cbind(SDvD.data$Pupa.ID, SDvD.data$Classification, SDvD.data$Mass..mg.,
                   SDvD.data$MRat25C..ul.h., log(SDvD.data$MRat25C..ul.h.), rep(25,length(SDvD.data$PupaID)))
SDvD.data2 <- as.data.frame(rbind(SDvD.cold, SDvD.warm))
colnames(SDvD.data2) <- c("Pupa.ID", "Classification", "Mass", "MR", "logMR", "Temperature")
SDvD.data2$Mass <- as.numeric(as.character(SDvD.data2$Mass))
SDvD.data2$MR <- as.numeric(as.character(SDvD.data2$MR))
SDvD.data2$logMR <- as.numeric(as.character(SDvD.data2$logMR))
SDvD.data2$Temperature <- as.numeric(as.character(SDvD.data2$Temperature))


#2. Fit nonlinear mixed models for met rate

fm<-lmer( logMR ~ Classification*Temperature + Mass + (1|Pupa.ID), data=SDvD.data2) 

#test fixed effects using 
drop1(fm)

# boundary (singular) fit: see ?isSingular
# Single term deletions
# 
# Model:
#   logMR ~ Classification * Temperature + Mass + (1 | Pupa.ID)
# npar    AIC
# <none>                          233.01
# Mass                          1 255.47
# Classification:Temperature    1 269.36

## the output suggests that the full model with the interaction and 
## including the body mass covariate is the best fit (lowest AIC). 

#3. Estimate slopes of model terms using contrasts

#create contrast vectors; the columns in the design matrix are"
#  Intercept, ClassificationSD, Temperature, Mass, and Classification:Temperature
conMat<-cbind(c(0,0,1,0,0),
              c(0,0,1,0,1))
colnames(conMat)<-c('SlopeForDia','SlopeForSD')
# First column is the contrast vector estimating the slope for diapause, second column for shallow diapause

library(multcomp)
a<-glht(fm,linfct=t(conMat))
summary(a)

# Simultaneous Tests for General Linear Hypotheses
# 
# Fit: lmer(formula = logMR ~ Classification * Temperature + Mass + 
#             (1 | Pupa.ID), data = SDvD.data2)
# 
# Linear Hypotheses:
#   Estimate Std. Error z value Pr(>|z|)    
# SlopeForDia == 0 0.084365   0.004664   18.09   <1e-10 ***
#   SlopeForSD == 0  0.127903   0.004774   26.79   <1e-10 ***
#   ---
#   Signif. codes:  0 â***â 0.001 â**â 0.01 â*â 0.05 â.â 0.1 â â 1
# (Adjusted p values reported -- single-step method)

## Above, 0.084 and 0.128 are the slope estimated for diapause and shallow diapause, respectively.

#4. Calculate point estimate of Q10

#The above slopes are for log(MR) as a function of temperature.
#To convert these slopes into Q10 values, we use:
#log(Q10) = 10*slope(fold-change in log(MR) with a 10 degree increase in temperature)
#Q10 = exp(10*slope)

Q10.D <- exp(10*0.084365)
Q10.SD <- exp(10*0.127903)

#print values
c(Q10.D, Q10.SD)
#2.324837, 3.593153

#5. Calculate confidence intervals for Q10

confint(a)
# Simultaneous Confidence Intervals
# 
# Fit: lmer(formula = logMR ~ Classification * Temperature + Mass + 
#             (1 | Pupa.ID), data = SDvD.data2)
# 
# Quantile = 2.2364
# 95% family-wise confidence level
# 
# 
# Linear Hypotheses:
#                 Estimate lwr     upr    
# SlopeForDia == 0 0.08436  0.07393 0.09480
# SlopeForND == 0  0.12790  0.11723 0.13858

b<-confint(a)
mat<-b$confint

## 95% CI for Diapause 

#point estimate Q10
intercept<-fixef(fm)[1]
exp( coef(a)[1]*10+intercept )/exp(intercept)
# 2.324829  #same as calculated in step 4

#lower 95%CI
exp( mat[1,2]*10 + intercept) / exp(intercept)
# 2.094542 

#upper 95%CI
exp( mat[1,3]*10 + intercept) / exp(intercept)
# 2.580434

## 95% CI for Shallow Diapause
#point estimate Q10
intercept<-fixef(fm)[1] + fixef(fm)[2]
exp( coef(a)[2]*10+intercept )/exp(intercept)
# 3.59316 #same as calculated in step 4

#lower 95%CI
exp( mat[2,2]*10 + intercept) / exp(intercept)
# 3.229303 

#upper 95%CI
exp( mat[2,3]*10 + intercept) / exp(intercept)
# 3.998015 

## so, 95% CIs are 2.09 - 2.58  (diapause) and 3.23 - 4.00 (shallow diapause)

########################################################
#                                                      #
#        Metabolic rate at 4 C over time               #
#                                                      #
########################################################

#read in data
#remove first row in the csv file before reading in data
my.data <- read.csv("MRat4Covertime.csv", stringsAsFactors = FALSE)
str(my.data)

#restructure data to make time a column variable
my.data.1 <- cbind(my.data[, c(1:5,6)], rep(1, length(my.data$Pupa.ID))) 
colnames(my.data.1) <- c("Expt", "Pupa.ID", "Classification", "Age.at.chill", "Mass", "MR", "Time..d.") 
my.data.2 <- cbind(my.data[, c(1:5,7)], rep(2, length(my.data$Pupa.ID)))
colnames(my.data.2) <- c("Expt", "Pupa.ID", "Classification", "Age.at.chill", "Mass", "MR", "Time..d.")
my.data.7 <- cbind(my.data[, c(1:5,8)], rep(7, length(my.data$Pupa.ID)))
colnames(my.data.7) <- c("Expt", "Pupa.ID", "Classification", "Age.at.chill", "Mass", "MR", "Time..d.")
my.data.14 <- cbind(my.data[, c(1:5,9)], rep(14, length(my.data$Pupa.ID)))
colnames(my.data.14) <- c("Expt", "Pupa.ID", "Classification", "Age.at.chill", "Mass", "MR", "Time..d.")
my.data.28 <- cbind(my.data[, c(1:5,10)], rep(28, length(my.data$Pupa.ID)))
colnames(my.data.28) <- c("Expt", "Pupa.ID", "Classification", "Age.at.chill", "Mass", "MR", "Time..d.")
my.data.56 <- cbind(my.data[, c(1:5,11)], rep(56, length(my.data$Pupa.ID)))
colnames(my.data.56) <- c("Expt", "Pupa.ID", "Classification", "Age.at.chill", "Mass", "MR", "Time..d.")

my.data2 <- as.data.frame(rbind(my.data.1, my.data.2, my.data.7,
                                my.data.14, my.data.28, my.data.56))
colnames(my.data2) <- c("Expt", "Pupa.ID", "Classification", "Age.at.chill","Mass", "MR", "Time..d.")
my.data2$Mass <- as.numeric(as.character(my.data2$Mass))
my.data2$MR <- as.numeric(as.character(my.data2$MR))
my.data2$Time..d. <- as.numeric(as.character(my.data2$Time..d.))

#remove individuals with incomplete datasets
s <- which(is.na(my.data2$MR)) #check for rows with missing MR data
s2 <- my.data2$Pupa.ID[s] #check which pupa IDs are associated with those rows
s3<- s2[!duplicated(s2)] #remove duplicate pupa IDs
s4 <- which(my.data2$Pupa.ID %in% s3) #find row numbers in dataset with those pupa IDs
my.data3 <- my.data2[-s4,] #remove those rows

#subset data into the two experiments

##NDvD
NDvD.data <- subset(my.data3, my.data$Age.at.chill=="10 d")
length(NDvD.data$Pupa.ID[NDvD.data$Classification=="ND"])
length(NDvD.data$Pupa.ID[NDvD.data$Classification=="D"])
#number of ND and D individuals is the same (balanced) - 174 each

#make classification into a factor
NDvD.data$Classification <- factor(NDvD.data$Classification, levels=c("D", "ND"))
levels(NDvD.data$Classification)

##SDvD
SDvD.data <- subset(my.data3, my.data$Age.at.chill!="10 d")
length(SDvD.data$Pupa.ID[SDvD.data$Classification=="SD"])
length(SDvD.data$Pupa.ID[SDvD.data$Classification=="D"])
#number of SD and D individuals is not the same (unbalanced) - 216 vs. 240

#make classification into a factor
SDvD.data$Classification <- factor(SDvD.data$Classification, levels=c("D", "SD"))
levels(SDvD.data$Classification)

# check nonlinear function shape/fit
# ind<-NDvD.data$Pupa.ID=="H28"
# fit <- nls(MR ~ SSasymp(Time..d., yf, y0, log_alpha), data = NDvD.data[ind,])
# library(ggplot2)
# library(broom)
# library(lme4)
# qplot(Time..d.,MR, data = augment(fit)) + geom_line(aes(y = .fitted))

############# Diapause vs. non-diapause ###############

library(lme4)
library(MASS)

##Diapause pupae
#1. Fit model with random effects for all model parameters with an individual pupa grouping factor

fm<-nlmer(MR ~ SSasymp(Time..d., yf, y0, log_alpha) ~ (log_alpha|Pupa.ID) + (yf|Pupa.ID) + (y0|Pupa.ID),start = c(yf=0.01,y0=0.12,log_alpha=-2),data=NDvD.data[NDvD.data$Classification=="D",])
summary(fm)

#Nonlinear mixed model fit by maximum likelihood  ['nlmerMod']
#Formula: MR ~ SSasymp(Time..d., yf, y0, log_alpha) ~ (log_alpha | Pupa.ID) +      (yf | Pupa.ID) + (y0 | Pupa.ID)
#Data: NDvD.data[NDvD.data$Classification == "D", ]
#
#   AIC      BIC   logLik deviance df.resid 
#-1334.2  -1312.0    674.1  -1348.2      167 
#
#Scaled residuals: 
#  Min      1Q  Median      3Q     Max 
#-2.2701 -0.5367 -0.1009  0.5905  3.3996 
#
#Random effects:
#  Groups    Name      Variance  Std.Dev.
#Pupa.ID   log_alpha 6.656e-02 0.257985
#Pupa.ID.1 yf        0.000e+00 0.000000
#Pupa.ID.2 y0        4.366e-05 0.006608
#Residual            1.590e-05 0.003988
#Number of obs: 174, groups:  Pupa.ID, 29
#
#Fixed effects:
#          Estimate Std. Error   t value
#yf        -0.001469   0.002090    -0.703
#y0         0.019937   0.001318    15.128
#log_alpha -4.722001   0.002312 -2042.631
#
#Correlation of Fixed Effects:
#              yf     y0    
#y0        -0.176       
#log_alpha -0.036  0.004
#
#confidence intervals for parameter estimates using the Wald method
confint(fm, parm=c("log_alpha",'yf','y0'),method="Wald" ,level = 0.95,nsim = 1000)

#                   2.5 %      97.5 %
#  yf        -0.005566053  0.00262836
#  y0         0.017354146  0.02252017
#  log_alpha -4.726531841 -4.71747005


#2. Create confidence bands for model 
# modified from https://stats.stackexchange.com/questions/348253/r-lme4-nlmer-confidence-interval

plotBand<-function(fm) {
  library(MASS)
  fmVcov<-vcov(fm)
  fmParms<-fixef(fm)
  modelFun<-function(t,yf,y0,log_alpha) {
    y = yf + (y0 - yf)*exp( -exp(log_alpha)*t ) 
  }
  
  #Resample 10000 parameter estimates from fixed effects and cov matrix:
  pars.resamp <- mvrnorm(100000, mu = fmParms , Sigma = fmVcov)
  
  
  #Calculate y values using resampled parameters
  xvals <- seq(1, 56, length.out = 100)
  yvals <- apply(pars.resamp, 1, function(x)  modelFun(xvals, x[1], x[2], x[3]))
  
  #determine 2.5 and 97.5% quantiles of the 10000 y values at each x value
  dfCI <- data.frame(t(apply(yvals, 1, quantile, c(0.025,0.975))) )
  
  #Combine output in data frame
  output <- data.frame(x=xvals,
                       y=modelFun(xvals, fmParms[1], fmParms[2], fmParms[3]),
                       lower=dfCI$"X2.5.",
                       upper=dfCI$"X97.5.")
  
  library(ggplot2)
  ribPlot<-ggplot(output, aes(x=xvals))+geom_line(aes(y=y))+
    geom_ribbon(aes(ymin=lower, ymax=upper), fill="dodgerblue3", alpha=0.3) + ylim(0,0.09)
  return(output)
}

pdatD<-plotBand(fm)
write.table(pdatD, "MRovertimeCI_NDvD_Diapause.txt", sep="\t", row.names=F)
#the above table used to plot confidence bands in Fig. 2

####

##Non-diapause pupae:
#1. Fit model with random effects for all model parameters with an individual pupa grouping factor

fm<-nlmer(MR ~ SSasymp(Time..d., yf, y0, log_alpha) ~ (log_alpha|Pupa.ID) + (yf|Pupa.ID) + (y0|Pupa.ID),start = c(yf=0.01,y0=0.12,log_alpha=-2),data=NDvD.data[NDvD.data$Classification=="ND",])
summary(fm)

#Nonlinear mixed model fit by maximum likelihood  ['nlmerMod']
#Formula: MR ~ SSasymp(Time..d., yf, y0, log_alpha) ~ (log_alpha | Pupa.ID) +      (yf | Pupa.ID) + (y0 | Pupa.ID)
#Data: NDvD.data[NDvD.data$Classification == "ND", ]
#
#  AIC      BIC   logLik deviance df.resid 
#-999.2   -977.1    506.6  -1013.2      167 
#
#Scaled residuals: 
#  Min      1Q  Median      3Q     Max 
#-2.1251 -0.5819  0.0702  0.5076  3.4542 
#
#Random effects:
#  Groups    Name      Variance  Std.Dev. 
#Pupa.ID   log_alpha 5.246e-09 7.243e-05
#Pupa.ID.1 yf        1.246e-04 1.116e-02
#Pupa.ID.2 y0        9.384e-04 3.063e-02
#Residual            8.008e-05 8.949e-03
#Number of obs: 174, groups:  Pupa.ID, 29
#
#Fixed effects:
#       Estimate Std. Error t value
#yf         0.021899   0.002301   9.519
#y0         0.083076   0.005711  14.548
#log_alpha -2.028541   0.024003 -84.513
#
#Correlation of Fixed Effects:
#       yf     y0    
#y0        -0.026       
#log_alpha  0.097  0.054

confint(fm, parm=c("log_alpha",'yf','y0'),method="Wald" ,level = 0.95,nsim = 1000)
#               2.5 %      97.5 %
#yf         0.01739052  0.02640840
#y0         0.07188332  0.09426845
#log_alpha -2.07558512 -1.98149591

#2. Create confidence bands for model 

pdatND<-plotBand(fm)
write.table(pdatND, "MRovertimeCI_NDvD_Non-diapause.txt", sep="\t", row.names=F)
#the above table used to plot confidence bands in Fig. 2

############# Diapause vs. shallow diapause ###############

##Diapause pupae
#1. Fit model with random effects for all model parameters with an individual pupa grouping factor

fm<-nlmer(MR ~ SSasymp(Time..d., yf, y0, log_alpha) ~ (log_alpha|Pupa.ID) + (yf|Pupa.ID) + (y0|Pupa.ID),start = c(yf=0.01,y0=0.12,log_alpha=-2),data=SDvD.data[SDvD.data$Classification=="D",])
summary(fm)

#Nonlinear mixed model fit by maximum likelihood  ['nlmerMod']
#Formula: MR ~ SSasymp(Time..d., yf, y0, log_alpha) ~ (log_alpha | Pupa.ID) +      (yf | Pupa.ID) + (y0 | Pupa.ID)
#Data: SDvD.data[SDvD.data$Classification == "D", ]
#
#    AIC      BIC   logLik deviance df.resid 
#-1945.8  -1921.5    979.9  -1959.8      233 
#
#Scaled residuals: 
#  Min      1Q  Median      3Q     Max 
#-2.4642 -0.5696 -0.1062  0.4737  3.8199 
#
#Random effects:
#  Groups    Name      Variance  Std.Dev. 
#Pupa.ID   log_alpha 3.070e-05 5.541e-03
#Pupa.ID.1 yf        1.702e-11 4.126e-06
#Pupa.ID.2 y0        1.752e-05 4.185e-03
#Residual            1.237e-05 3.517e-03
#Number of obs: 240, groups:  Pupa.ID, 40
#
#Fixed effects:
#            Estimate Std. Error t value
#yf         0.0080407  0.0007268   11.06
#y0         0.0093360  0.0007452   12.53
#log_alpha -3.7756336  0.3083643  -12.24
#
#Correlation of Fixed Effects:
#              yf     y0    
#y0        -0.207       
#log_alpha  0.301  0.026


confint(fm, parm=c("log_alpha",'yf','y0'),method="Wald" ,level = 0.95,nsim = 1000)
#                2.5 %      97.5 %
#yf         0.00661624  0.00946519
#y0         0.00787532  0.01079662
#log_alpha -4.38001655 -3.17125072

#2. Create confidence bands for model 

pdatD<-plotBand(fm)
write.table(pdatD, "MRovertimeCI_SDvD_Diapause.txt", sep="\t", row.names=F)

####

##Shallow Diapause pupae
#1. Fit model with random effects for all model parameters with an individual pupa grouping factor

#full model wouldn't converge, but all curves seem to have similar asymtote
#remove random pupa affect on yf, seems to converge just fine

fm<-nlmer(MR ~ SSasymp(Time..d., yf, y0, log_alpha) ~ (log_alpha|Pupa.ID) + (y0|Pupa.ID),start = c(yf=0.03,y0=0.07,log_alpha=-1),data=SDvD.data[SDvD.data$Classification=="SD",])
summary(fm)

#Nonlinear mixed model fit by maximum likelihood  ['nlmerMod']
#Formula: MR ~ SSasymp(Time..d., yf, y0, log_alpha) ~ (log_alpha | Pupa.ID) +      (y0 | Pupa.ID)
#Data: SDvD.data[SDvD.data$Classification == "SD", ]
#
#    AIC      BIC   logLik deviance df.resid 
#-1299.9  -1279.7    656.0  -1311.9      210 
#
#Scaled residuals: 
#  Min      1Q  Median      3Q     Max 
#-2.4796 -0.5448 -0.0530  0.3966  3.9737 
#
#Random effects:
#  Groups    Name      Variance  Std.Dev.
#Pupa.ID   log_alpha 9.374e-01 0.968206
#Pupa.ID.1 y0        1.597e-03 0.039958
#Residual            5.439e-05 0.007375
#Number of obs: 216, groups:  Pupa.ID, 36
#
#Fixed effects:
#            Estimate Std. Error t value
#yf         0.0177671  0.0008432   21.07
#y0         0.0774943  0.0058969   13.14
#log_alpha -1.6938252  0.0074173 -228.36
#
#Correlation of Fixed Effects:
#             yf     y0    
#y0         0.076       
#log_alpha  0.008 -0.010

confint(fm, parm=c("log_alpha",'yf','y0'),method="Wald" ,level = 0.95,nsim = 1000)
#                2.5 %      97.5 %
#yf         0.01611453  0.01941966
#y0         0.06593648  0.08905203
#log_alpha -1.70836279 -1.67928765

#2. Create confidence bands for model 

pdatSD<-plotBand(fm)
write.table(pdatSD, "MRovertimeCI_SDvD_ShallowDiapause.txt", sep="\t", row.names=F)

#NDvD
NDvD.data$logMR <- log(NDvD.data$MR)

ND.model <- aov(logMR ~ Mass + Classification * Time..d. + Error(Pupa.ID), NDvD.data)
summary(ND.model)

#### Post-hoc tests to compare metabolic rates among groups at each time point ####
#performed on log-transformed metabolic rates to meet assumptions of normality

## Diapause vs. Non-diapause

NDvD.data$IndexVar <- paste(NDvD.data$Classification, NDvD.data$Time..d., sep="")
NDvD.data$IndexVar <- factor(NDvD.data$IndexVar, levels=c("D1", "D2", "D7", "D14", "D28", "D56",
                                                          "ND1", "ND2", "ND7", "ND14", "ND28", "ND56"))
pairwise.t.test(log(NDvD.data$MR), NDvD.data$IndexVar, paired=TRUE, p.adjust.method = "bonferroni")

#different between ND and D at all time points

#Diapause vs. Shallow Diapause

SDvD.data$IndexVar <- paste(SDvD.data$Classification, SDvD.data$Time..d., sep="")
SDvD.data$IndexVar <- factor(SDvD.data$IndexVar, levels=c("D1", "D2", "D7", "D14", "D28", "D56",
                                                          "SD1", "SD2", "SD7", "SD14", "SD28", "SD56"))
#need SD to = D for posthoc test to work.
#D has 40 individuals, SD has 36 individuals.
#solution: remove each 10th D individual

SDvD.data$Pupa.ID[SDvD.data$IndexVar=="D1"]
rem.1 <- which(SDvD.data$Pupa.ID=="X26" | SDvD.data$Pupa.ID=="M55" |
                 SDvD.data$Pupa.ID=="L11" | SDvD.data$Pupa.ID=="K60" )
SDvD.data <- SDvD.data[-rem.1,]

pairwise.t.test(log(SDvD.data$MR), SDvD.data$IndexVar, paired=TRUE, p.adjust.method = "bonferroni")

#different between SD and D at all time points

########################################################
#                                                      #
#           Supercooling Points (SCPs)                 #
#                                                      #
########################################################

#read in data
my.data <- read.csv("SCPs.csv")
str(my.data)

#ANCOVA with mass and experiment (pre-winter length) as covariates
my.model <- aov(my.data$SCP ~ my.data$Mass + my.data$Expt + my.data$Classification)
anova(my.model)

#Analysis of Variance Table
#
#Response: my.data$SCP
#                       Df  Sum Sq Mean Sq F value   Pr(>F)   
#my.data$Mass            1   3.837   3.837  0.8678 0.354811   
#my.data$Expt            1  37.329  37.329  8.4430 0.004921 **
#my.data$Classification  2   2.868   1.434  0.3243 0.724141   
#Residuals               69 305.073   4.421                    
#---
#  Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

##Age at which pupae enter fridge (Expt) affects SCP (older pupae = lower SCP)


########################################################
#                                                      #
#     Proportion Eclosion and Eclosion Time            #
#                                                      #
########################################################

#read in data
my.data <- read.csv("Eclosion.csv", stringsAsFactors = FALSE)
str(my.data)

########### Proportion Eclosion ###############

##Compare alive/dead pupae using a logistic regression with binary error distribution

#1. Code flies as alive or dead

#all eclosed and "undeveloped, alive" flies are alive
a <- which(my.data$Category=="Eclosed" | my.data$Category=="Undeveloped, alive") #rows with alive individuals
d <- which(my.data$Category=="Undeveloped, dead" | my.data$Category=="Developed, dead" | my.data$Category=="Dead") #rows with dead individuals
LiveDead1 <- vector(length=length(my.data$Category)) #empty logical vector
LiveDead1[a] <- 1 #enter 1 for all live individuals
LiveDead1[d] <- 0 #enter 0 for all dead individuals

#add LiveDead columns to dataframe
my.data$LiveDead1 <- LiveDead1

colnames(my.data) <- c("Expt", "Pupa.ID", "Classification", "Age.at.chill", "WeeksWinter", "Category", "EclosionTime")

##Diapause vs. Non-diapause

#1. Subset data and make time in winter a factor
NDvD <- my.data[my.data$Expt=="NDvD",]
NDvD$WeeksWinter <- as.factor(NDvD$WeeksWinter)

#2. Fit logistic regression model
ND.model <- glm(LiveDead1 ~ Classification*WeeksWinter, family="binomial", data=NDvD)

drop1(ND.model)
#Single term deletions
#
#Model:
#  LiveDead1 ~ Classification * WeeksWinter
#                            Df Deviance    AIC
#<none>                           263.92 275.92
#Classification:WeeksWinter  1    265.20 273.20

#better to remove interaction term because the AIC is lowest

ND.model <- glm(LiveDead1 ~ Classification + WeeksWinter, family="binomial", data=NDvD)
summary(ND.model)

#Call:
#  glm(formula = LiveDead1 ~ Classification + WeeksWinter, family = "binomial", 
#      data = NDvD)
#
#Deviance Residuals: 
#  Min       1Q   Median       3Q      Max  
#-1.7202  -0.9871  -0.6191   1.0227   1.8688  
#
#Coefficients:
#                     Estimate Std. Error z value Pr(>|z|)    
#(Intercept)           1.2211     0.3067   3.981 6.85e-05 ***
#ClassificationND     -1.6868     0.3034  -5.560 2.70e-08 ***
#WeeksWinter16        -1.0889     0.3707  -2.937  0.00331 ** 
#WeeksWinter24        -0.8456     0.3626  -2.332  0.01970 *  
#  ---
#  Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
#
#(Dispersion parameter for binomial family taken to be 1)
#
#Null deviance: 307.95  on 223  degrees of freedom
#Residual deviance: 265.21  on 220  degrees of freedom
#AIC: 273.21
#
#Number of Fisher Scoring iterations: 4

####

##Diapause vs. Shallow Diapause

#1. Subset data and make time in winter a factor
SDvD <- my.data[my.data$Expt=="SDvD",]
SDvD$WeeksWinter <- as.factor(SDvD$WeeksWinter)

#2. Fit logistic regression model
SD.model <- glm(LiveDead1 ~ Classification*WeeksWinter, family="binomial", data=SDvD)

drop1(SD.model)
#Single term deletions
#
#Model:
#  LiveDead1 ~ Category * WeeksWinter
#                             Df Deviance    AIC
#<none>                          198.80 210.80
#Classification:WeeksWinter  1   204.65 212.65

#better to keep interaction; that model has the lowest AIC

summary(SD.model)

#Call:
#  glm(formula = LiveDead1 ~ Classification * WeeksWinter, family = "binomial", 
#      data = SDvD)
#
#Deviance Residuals: 
#  Min       1Q   Median       3Q      Max  
#-1.0489  -0.7215  -0.4952  -0.4854   2.0963  
#
#Coefficients:
#  Estimate Std. Error z value Pr(>|z|)    
#(Intercept)                     -1.2130     0.3434  -3.532 0.000412 ***
#ClassificationSD                0.2516     0.4736   0.531 0.595207    
#WeeksWinter16                   -0.8664     0.7021  -1.234 0.217176    
#WeeksWinter24                    0.9029     0.5249   1.720 0.085414 .  
#ClassificationSD:WeeksWinter16  -0.2516     0.9870  -0.255 0.798787    
#ClassificationSD:WeeksWinter24  -1.9783     0.8710  -2.271 0.023127 *  
#  ---
#  Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
#
#(Dispersion parameter for binomial family taken to be 1)
#
#Null deviance: 211.26  on 200  degrees of freedom
#Residual deviance: 198.80  on 195  degrees of freedom
#AIC: 210.8
#
#Number of Fisher Scoring iterations: 4


############# Eclosion Time ##################

#Compare eclosion time using a Mann-Whitney U test.
#Pairwise comparison with correction for multiple tests.
#From https://www.statmethods.net/stats/nonparametric.html 

#subset data further (only working with eclosed flies)
my.data <- my.data[my.data$Category=="Eclosed",]
str(my.data)

## Diapause vs. Non-diapause
NDvD <- my.data[my.data$Expt=="NDvD",]
NDvD$Category <- factor(NDvD$Category, levels = c("D", "ND"))
NDvD$WeeksWinter <- factor(NDvD$WeeksWinter)

#2 months (8 weeks) comparison
NDvD.2 <- wilcox.test(NDvD$EclosionTime[NDvD$Category=="D" & NDvD$WeeksWinter=="8"],
                      NDvD$EclosionTime[NDvD$Category=="ND" & NDvD$WeeksWinter=="8"],
                      alternative = "greater")

#4 months (16 weeks) comparison
NDvD.4 <- wilcox.test(NDvD$EclosionTime[NDvD$Category=="D" & NDvD$WeeksWinter=="16"],
                      NDvD$EclosionTime[NDvD$Category=="ND" & NDvD$WeeksWinter=="16"],
                      alternative = "greater")

#6 months (24 weeks) comparison
NDvD.6 <- wilcox.test(NDvD$EclosionTime[NDvD$Category=="D" & NDvD$WeeksWinter=="24"],
                      NDvD$EclosionTime[NDvD$Category=="ND" & NDvD$WeeksWinter=="24"],
                      alternative = "greater")

#print corrected p-values
NDvD.2$p.value*3; NDvD.4$p.value*3; NDvD.6$p.value*3
# 3.904256e-05, 0.03445233, 0.2570565

#ND across time
ND2v4<- wilcox.test(NDvD$EclosionTime[NDvD$Category=="ND" & NDvD$WeeksWinter=="8"],
                    NDvD$EclosionTime[NDvD$Category=="ND" & NDvD$WeeksWinter=="16"])

ND4v6 <- wilcox.test(NDvD$EclosionTime[NDvD$Category=="ND" & NDvD$WeeksWinter=="16"],
                     NDvD$EclosionTime[NDvD$Category=="ND" & NDvD$WeeksWinter=="24"])

#print corrected p-values
2*ND2v4$p.value; 2*ND4v6$p.value
#0.001893492, 1.01663

####

##Diapause vs. Shallow Diapause

SDvD <- my.data[my.data$Expt=="SDvD",]
SDvD$Category <- factor(SDvD$Category, levels = c("D", "SD"))
SDvD$WeeksWinter <- factor(SDvD$WeeksWinter)

#2 months (8 weeks) comparison
SDvD.2 <- wilcox.test(SDvD$EclosionTime[SDvD$Category=="D" & SDvD$WeeksWinter=="8"],
                      SDvD$EclosionTime[SDvD$Category=="SD" & SDvD$WeeksWinter=="8"],
                      alternative = "greater")

#4 months (16 weeks) comparison
SDvD.4 <- wilcox.test(SDvD$EclosionTime[SDvD$Category=="D" & SDvD$WeeksWinter=="16"],
                      SDvD$EclosionTime[SDvD$Category=="SD" & SDvD$WeeksWinter=="16"],
                      alternative = "greater")

#no test for 6 months/24 weeks winter (only 1 data point in each group)

#print corrected p-values
SDvD.2$p.value*2; SDvD.4$p.value*2 
# 0.006638256, 0.4

#SD across time
SD2v4<- wilcox.test(SDvD$EclosionTime[SDvD$Category=="SD" & SDvD$WeeksWinter=="8"],
                    SDvD$EclosionTime[SDvD$Category=="SD" & SDvD$WeeksWinter=="16"])

#print p-value
SD2v4$p.value
#0.7664565
